{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d978f5eb-608a-443b-85ec-e9c5bf56a7fb",
   "metadata": {},
   "source": [
    "## Transformations in Spark (DataFrame API and Spark SQL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c252bb9-5594-4ea2-95f5-3682049fb3d4",
   "metadata": {},
   "source": [
    "## DataFrame API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d30de127-a0bc-401e-b196-f17ef7aa1b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53f6d3a2-18e8-4f30-b649-e144f3e0f169",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "25/11/17 22:55:31 WARN Utils: Your hostname, Shrees-MacBook-Air.local, resolves to a loopback address: 127.0.0.1; using 10.183.253.103 instead (on interface en0)\n",
      "25/11/17 22:55:31 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/11/17 22:55:31 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://10.183.253.103:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v4.0.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[5]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>DataFrameAPIandSQL</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x117d66750>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark = SparkSession.builder.master (\"local[5]\")\\\n",
    "        .appName(\"DataFrameAPIandSQL\")\\\n",
    "        .getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ea5a764-3e82-4389-a9c7-2c3e95e66bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = spark.read.format(\"csv\")\\\n",
    "    .option(\"header\",\"true\")\\\n",
    "    .option(\"inferschema\",\"true\")\\\n",
    "    .option(\"mode\",\"PERMISSIVE\")\\\n",
    "    .load(\"data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35ee794c-c5ca-4a43-b7d8-87436f42eb38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+---+------+------------+--------+\n",
      "| id|    name|age|salary|     address| nominee|\n",
      "+---+--------+---+------+------------+--------+\n",
      "|  1|  Manish| 26| 75000|       bihar|nominee1|\n",
      "|  2|  Nikita| 23|100000|uttarpradesh|nominee2|\n",
      "|  3|  Pritam| 22|150000|   Bangalore|   India|\n",
      "|  4|Prantosh| 17|200000|     Kolkata|   India|\n",
      "|  5|  Vikash| 31|300000|        NULL| nominee|\n",
      "+---+--------+---+------+------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b5a1004-7994-41e6-81c8-3f0cfaf03944",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_schema = StructType(\n",
    "                            [StructField(\"id\",IntegerType(),True),\n",
    "                             StructField(\"name\",StringType(),True),\n",
    "                             StructField(\"age\",IntegerType(),True),\n",
    "                             StructField(\"salary\",IntegerType(),True),\n",
    "                             StructField(\"address\",StringType(),True),\n",
    "                             StructField(\"nominee\",StringType(),True),\n",
    "                             StructField(\"corrupt_record\",StringType(),True)\n",
    "                            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b22cf6e-90a6-4e3b-8a71-9c0771fb6e50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- salary: integer (nullable = true)\n",
      " |-- address: string (nullable = true)\n",
      " |-- nominee: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42f62379-78ce-436a-9e8c-cf6ac5e538af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|    name|\n",
      "+--------+\n",
      "|  Manish|\n",
      "|  Nikita|\n",
      "|  Pritam|\n",
      "|Prantosh|\n",
      "|  Vikash|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_df.select(\"name\").show() # String Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a51b6ca-984d-42c3-affc-4825c7dd6a24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|    name|\n",
      "+--------+\n",
      "|  Manish|\n",
      "|  Nikita|\n",
      "|  Pritam|\n",
      "|Prantosh|\n",
      "|  Vikash|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_df.select(col(\"name\")).show() # Column Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "701b0a04-c2bf-4204-af1a-25db40dfaab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+---+\n",
      "| id|    name|age|\n",
      "+---+--------+---+\n",
      "|  1|  Manish| 26|\n",
      "|  2|  Nikita| 23|\n",
      "|  3|  Pritam| 22|\n",
      "|  4|Prantosh| 17|\n",
      "|  5|  Vikash| 31|\n",
      "+---+--------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_df.select('id', 'name', 'age').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "53baee65-dfaf-4dba-9c9d-9e4c6bd5f9d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+---+\n",
      "| id|    name|age|\n",
      "+---+--------+---+\n",
      "|  1|  Manish| 26|\n",
      "|  2|  Nikita| 23|\n",
      "|  3|  Pritam| 22|\n",
      "|  4|Prantosh| 17|\n",
      "|  5|  Vikash| 31|\n",
      "+---+--------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_df.select(col('id'), col('name'), col('age')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7ac09fc9-575b-4178-aa91-978b2a71a6aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|(id + 5)|\n",
      "+--------+\n",
      "|       6|\n",
      "|       7|\n",
      "|       8|\n",
      "|       9|\n",
      "|      10|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_df.select(expr(\"id + 5\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf13959-3adb-47ee-a07b-b1b39f10182c",
   "metadata": {},
   "source": [
    "## Spark SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "39ceaecb-0286-4d2e-9fd6-8a549cc13433",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.createOrReplaceTempView(\"data_tbl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "33276d43-3db7-4e77-aba7-0462c0149d40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+---+------+------------+--------+\n",
      "| id|    name|age|salary|     address| nominee|\n",
      "+---+--------+---+------+------------+--------+\n",
      "|  1|  Manish| 26| 75000|       bihar|nominee1|\n",
      "|  2|  Nikita| 23|100000|uttarpradesh|nominee2|\n",
      "|  3|  Pritam| 22|150000|   Bangalore|   India|\n",
      "|  4|Prantosh| 17|200000|     Kolkata|   India|\n",
      "|  5|  Vikash| 31|300000|        NULL| nominee|\n",
      "+---+--------+---+------+------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql (\"\"\"\n",
    "\n",
    "Select * from data_tbl\n",
    "\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5278e447-4fcf-4a9f-99e3-d023e186ad91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- salary: integer (nullable = true)\n",
      " |-- address: string (nullable = true)\n",
      " |-- nominee: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc86ca2-0235-439b-a946-98a9d7f3caf3",
   "metadata": {},
   "source": [
    "## Transformations in Spark (Spark DataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "63e9ef34-9514-480b-bde3-468abd90d6d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+---+\n",
      "|employee_id|    name|age|\n",
      "+-----------+--------+---+\n",
      "|          1|  Manish| 26|\n",
      "|          2|  Nikita| 23|\n",
      "|          3|  Pritam| 22|\n",
      "|          4|Prantosh| 17|\n",
      "|          5|  Vikash| 31|\n",
      "+-----------+--------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## 1. Aliasing - Alternate / Replace name of the existing column\n",
    "data_df.select(col(\"id\").alias(\"employee_id\"), \"name\", \"age\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4ebb96b7-8bc1-4873-87b7-e79af1ba97fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+---+------+-------+-------+\n",
      "| id|    name|age|salary|address|nominee|\n",
      "+---+--------+---+------+-------+-------+\n",
      "|  4|Prantosh| 17|200000|Kolkata|  India|\n",
      "|  5|  Vikash| 31|300000|   NULL|nominee|\n",
      "+---+--------+---+------+-------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## 2. Filter / Where\n",
    "data_df.filter(col(\"salary\")>150000).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b739fbc0-fe33-4fbb-99e3-13ad4ea52741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+---+------+-------+-------+\n",
      "| id|    name|age|salary|address|nominee|\n",
      "+---+--------+---+------+-------+-------+\n",
      "|  4|Prantosh| 17|200000|Kolkata|  India|\n",
      "+---+--------+---+------+-------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## 'and' / 'or'\n",
    "data_df.filter((col(\"salary\")>150000) & (col(\"age\")<18)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f1c893b9-3da5-4495-8acd-fc4d61a88a99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+---+------+------------+--------+---------+\n",
      "| id|    name|age|salary|     address| nominee|last_name|\n",
      "+---+--------+---+------+------------+--------+---------+\n",
      "|  1|  Manish| 26| 75000|       bihar|nominee1|    Kumar|\n",
      "|  2|  Nikita| 23|100000|uttarpradesh|nominee2|    Kumar|\n",
      "|  3|  Pritam| 22|150000|   Bangalore|   India|    Kumar|\n",
      "|  4|Prantosh| 17|200000|     Kolkata|   India|    Kumar|\n",
      "|  5|  Vikash| 31|300000|        NULL| nominee|    Kumar|\n",
      "+---+--------+---+------+------------+--------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## 3. Literal\n",
    "data_df.select(\"*\", lit(\"Kumar\").alias(\"last_name\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "95db11dd-147e-46f7-ac5b-4b579fa471f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+---+------+------------+--------+-------+\n",
      "| id|    name|age|salary|     address| nominee|surname|\n",
      "+---+--------+---+------+------------+--------+-------+\n",
      "|  1|  Manish| 26| 75000|       bihar|nominee1|  Singh|\n",
      "|  2|  Nikita| 23|100000|uttarpradesh|nominee2|  Singh|\n",
      "|  3|  Pritam| 22|150000|   Bangalore|   India|  Singh|\n",
      "|  4|Prantosh| 17|200000|     Kolkata|   India|  Singh|\n",
      "|  5|  Vikash| 31|300000|        NULL| nominee|  Singh|\n",
      "+---+--------+---+------+------------+--------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## 4. With Column\n",
    "data_df.withColumn(\"surname\", lit(\"Singh\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d1907c28-e9de-4597-90d9-9d6e2e7ed6c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+---+------+------------+--------+\n",
      "|employee_id|    name|age|salary|     address| nominee|\n",
      "+-----------+--------+---+------+------------+--------+\n",
      "|          1|  Manish| 26| 75000|       bihar|nominee1|\n",
      "|          2|  Nikita| 23|100000|uttarpradesh|nominee2|\n",
      "|          3|  Pritam| 22|150000|   Bangalore|   India|\n",
      "|          4|Prantosh| 17|200000|     Kolkata|   India|\n",
      "|          5|  Vikash| 31|300000|        NULL| nominee|\n",
      "+-----------+--------+---+------+------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_df.withColumnRenamed(\"id\", \"employee_id\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "20a23ec6-c8ef-4289-9ac8-eb22ab7e2cc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+---+------+------------+--------+\n",
      "|employee_id|    name|age|salary|     address| nominee|\n",
      "+-----------+--------+---+------+------------+--------+\n",
      "|          1|  Manish| 26| 75000|       bihar|nominee1|\n",
      "|          2|  Nikita| 23|100000|uttarpradesh|nominee2|\n",
      "|          3|  Pritam| 22|150000|   Bangalore|   India|\n",
      "|          4|Prantosh| 17|200000|     Kolkata|   India|\n",
      "|          5|  Vikash| 31|300000|        NULL| nominee|\n",
      "+-----------+--------+---+------+------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## 5. Casting data types \n",
    "new_data_df = data_df.withColumnRenamed(\"id\", \"employee_id\")\n",
    "new_data_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf78e82-eb7a-476a-8345-e39f4fdd6151",
   "metadata": {},
   "source": [
    "## Transformation (Spark SQL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9bdb4767-b571-4871-b553-4797fd639cae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+---+------+------------+--------+\n",
      "| id|    name|age|salary|     address| nominee|\n",
      "+---+--------+---+------+------------+--------+\n",
      "|  1|  Manish| 26| 75000|       bihar|nominee1|\n",
      "|  2|  Nikita| 23|100000|uttarpradesh|nominee2|\n",
      "|  3|  Pritam| 22|150000|   Bangalore|   India|\n",
      "|  4|Prantosh| 17|200000|     Kolkata|   India|\n",
      "|  5|  Vikash| 31|300000|        NULL| nominee|\n",
      "+---+--------+---+------+------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_df.createOrReplaceTempView(\"data_tbl\")\n",
    "\n",
    "spark.sql (\"\"\"\n",
    "\n",
    "Select * from data_tbl\n",
    "\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "0863730e-a581-4195-9989-a3632d0f40f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+---+------+-------+-------+\n",
      "| id|    name|age|salary|address|nominee|\n",
      "+---+--------+---+------+-------+-------+\n",
      "|  4|Prantosh| 17|200000|Kolkata|  India|\n",
      "+---+--------+---+------+-------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql (\"\"\"\n",
    "\n",
    "select * from data_tbl where salary > 150000 and age < 18\n",
    "\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "5cbca8d2-a124-4c0c-a354-7ba51a3511d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+------+------------+\n",
      "| id|    name|salary|     address|\n",
      "+---+--------+------+------------+\n",
      "|  1|  Manish| 75000|       bihar|\n",
      "|  2|  Nikita|100000|uttarpradesh|\n",
      "|  3|  Pritam|150000|   Bangalore|\n",
      "|  4|Prantosh|200000|     Kolkata|\n",
      "|  5|  Vikash|300000|        NULL|\n",
      "+---+--------+------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql (\"\"\"\n",
    "\n",
    "select id, name, salary, address from data_tbl\n",
    "\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c057ff-351b-4352-83b4-8c0b77140519",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
