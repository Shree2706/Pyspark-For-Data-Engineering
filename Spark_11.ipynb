{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e095450-2677-419a-84b2-f7664bc3dadf",
   "metadata": {},
   "source": [
    "## Group By in Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dddd121e-6f7f-4b55-a2a1-8f0fe2e913c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cbdf91c1-9824-4ccc-bb86-5e4714a370a0",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "25/11/19 22:42:43 WARN Utils: Your hostname, Shrees-MacBook-Air.local, resolves to a loopback address: 127.0.0.1; using 10.183.253.103 instead (on interface en0)\n",
      "25/11/19 22:42:43 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/11/19 22:42:44 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://10.183.253.103:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v4.0.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>GroupByinSpark</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x12f9afec0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark = (\n",
    "    SparkSession\n",
    "    .builder\\\n",
    "    .appName(\"GroupByinSpark\")\\\n",
    "    .master(\"local[*]\")\\\n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb07d98d-a3c8-4284-97a8-53828dbf60e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "emp_data = [(1,'manish',50000,'IT'),\n",
    "(2,'vikash',60000,'sales'),\n",
    "(3,'raushan',70000,'marketing'),\n",
    "(4,'mukesh',80000,'IT'),\n",
    "(5,'pritam',90000,'sales'),\n",
    "(6,'nikita',45000,'marketing'),\n",
    "(7,'ragini',55000,'marketing'),\n",
    "(8,'rakesh',100000,'IT'),\n",
    "(9,'aditya',65000,'IT'),\n",
    "(10,'rahul',50000,'marketing')]\n",
    "\n",
    "emp_schema = ['id', 'name', 'sal', 'dept']\n",
    "\n",
    "emp_df = spark.createDataFrame(schema=emp_schema, data=emp_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03367081-ed88-49f1-b5c0-040f1267c1ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 0:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+------+---------+\n",
      "| id|   name|   sal|     dept|\n",
      "+---+-------+------+---------+\n",
      "|  1| manish| 50000|       IT|\n",
      "|  2| vikash| 60000|    sales|\n",
      "|  3|raushan| 70000|marketing|\n",
      "|  4| mukesh| 80000|       IT|\n",
      "|  5| pritam| 90000|    sales|\n",
      "|  6| nikita| 45000|marketing|\n",
      "|  7| ragini| 55000|marketing|\n",
      "|  8| rakesh|100000|       IT|\n",
      "|  9| aditya| 65000|       IT|\n",
      "| 10|  rahul| 50000|marketing|\n",
      "+---+-------+------+---------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "emp_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd3e7538-caf9-4d96-9531-fb6534c020fa",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+\n",
      "|     dept|sum(sal)|\n",
      "+---------+--------+\n",
      "|       IT|  295000|\n",
      "|    sales|  150000|\n",
      "|marketing|  220000|\n",
      "+---------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp_df.groupBy(\"dept\")\\\n",
    "    .agg(sum(\"sal\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1777a57c-e6e4-46c5-8665-dcf38fca276c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Leetcode Question\n",
    "\n",
    "emp_data_1 = [(1,'manish',50000,'IT','india'),\n",
    "(2,'vikash',60000,'sales','us'),\n",
    "(3,'raushan',70000,'marketing','india'),\n",
    "(4,'mukesh',80000,'IT','us'),\n",
    "(5,'pritam',90000,'sales','india'),\n",
    "(6,'nikita',45000,'marketing','us'),\n",
    "(7,'ragini',55000,'marketing','india'),\n",
    "(8,'rakesh',100000,'IT','us'),\n",
    "(9,'aditya',65000,'IT','india'),\n",
    "(10,'rahul',50000,'marketing','us')]\n",
    "\n",
    "emp_schema_1 = ['id', 'name', 'sal', 'dept', 'country']\n",
    "\n",
    "emp_df1 = spark.createDataFrame(schema=emp_schema_1, data=emp_data_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "68ee3015-af14-4586-a7a9-99837e900bee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+------+---------+-------+\n",
      "| id|   name|   sal|     dept|country|\n",
      "+---+-------+------+---------+-------+\n",
      "|  1| manish| 50000|       IT|  india|\n",
      "|  2| vikash| 60000|    sales|     us|\n",
      "|  3|raushan| 70000|marketing|  india|\n",
      "|  4| mukesh| 80000|       IT|     us|\n",
      "|  5| pritam| 90000|    sales|  india|\n",
      "|  6| nikita| 45000|marketing|     us|\n",
      "|  7| ragini| 55000|marketing|  india|\n",
      "|  8| rakesh|100000|       IT|     us|\n",
      "|  9| aditya| 65000|       IT|  india|\n",
      "| 10|  rahul| 50000|marketing|     us|\n",
      "+---+-------+------+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp_df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "930f9e67-56bc-47c3-b5aa-d886b25453b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------+--------+\n",
      "|     dept|country|sum(sal)|\n",
      "+---------+-------+--------+\n",
      "|       IT|  india|  115000|\n",
      "|    sales|     us|   60000|\n",
      "|marketing|  india|  125000|\n",
      "|    sales|  india|   90000|\n",
      "|       IT|     us|  180000|\n",
      "|marketing|     us|   95000|\n",
      "+---------+-------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp_df1.groupBy(\"dept\",\"country\")\\\n",
    "    .agg(sum(\"sal\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509a3ad7-008b-4b9c-a141-5e931162100f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
